# ClawTower v0.3.1 Implementation Plan

> **For Claude:** REQUIRED SUB-SKILL: Use superpowers:executing-plans to implement this plan task-by-task.

**Goal:** Ship one release addressing all 6 critical gaps â€” noise reduction, process attribution, update signing, network baseline, compiler false positives, and health heartbeat.

**Architecture:** Surgical changes across existing modules. Fuzzy dedup in aggregator, auid extraction in auditd, Ed25519 signing in update pipeline, config-driven network allowlists, compiler/linker allowlisting in behavior, health endpoint + periodic Slack heartbeat, alert persistence to JSONL, SSH monitoring via journald, scan timeouts, `clawtower config` CLI, and docs.

**Tech Stack:** Rust, ed25519-dalek, ipnet (new deps), tokio, serde, existing ClawTower architecture

**Current version:** 0.1.9 â†’ target 0.2.0

---

## Task 1: Bump Version

**Files:**
- Modify: `Cargo.toml:3`

**Step 1: Update version**

Change `version = "0.1.9"` to `version = "0.2.0"` in `Cargo.toml`.

**Step 2: Commit**

```bash
git add Cargo.toml
git commit -m "chore: bump version to 0.2.0"
```

---

## Task 2: Fuzzy Alert Deduplication

The current dedup key is exact `source:message` match. Alerts with varying PIDs, timestamps, or counts bypass dedup. Replace with a "shape" key that normalizes volatile tokens.

**Files:**
- Modify: `src/aggregator.rs`

**Step 1: Write the failing test**

Add to `src/aggregator.rs` tests:

```rust
#[test]
fn test_fuzzy_dedup_strips_numbers() {
    let mut agg = Aggregator::new(AggregatorConfig::default());
    let a1 = make_alert("scan:cron", "Found 3 suspicious crontab entries for uid 1000", Severity::Warning);
    let a2 = make_alert("scan:cron", "Found 4 suspicious crontab entries for uid 1000", Severity::Warning);
    
    assert!(agg.process(a1).is_some());
    assert!(agg.process(a2).is_none()); // fuzzy match â€” same shape
}

#[test]
fn test_fuzzy_dedup_different_shapes_pass() {
    let mut agg = Aggregator::new(AggregatorConfig::default());
    let a1 = make_alert("auditd", "exec: curl http://api.example.com", Severity::Info);
    let a2 = make_alert("auditd", "exec: wget http://evil.com", Severity::Info);
    
    assert!(agg.process(a1).is_some());
    assert!(agg.process(a2).is_some()); // different commands, different shape
}
```

**Step 2: Run test to verify it fails**

```bash
cargo test test_fuzzy_dedup -- --nocapture
```

Expected: FAIL â€” a2 passes through because exact message differs.

**Step 3: Implement fuzzy dedup key**

Replace the `dedup_key` function:

```rust
/// Generate a dedup key that normalizes volatile tokens (numbers, PIDs, timestamps)
/// so structurally identical alerts with different counts/IDs are treated as duplicates.
fn dedup_key(alert: &Alert) -> String {
    let shape: String = alert.message.chars().map(|c| {
        if c.is_ascii_digit() { '#' } else { c }
    }).collect();
    format!("{}:{}", alert.source, shape)
}
```

**Step 4: Run tests**

```bash
cargo test -- --nocapture
```

Expected: All pass including new fuzzy dedup tests.

**Step 5: Add scan-specific dedup window**

Add `scan_dedup_window` to `AggregatorConfig`:

```rust
pub struct AggregatorConfig {
    pub dedup_window: Duration,
    /// Longer dedup window for scan-sourced alerts (periodic scans repeat)
    pub scan_dedup_window: Duration,
    pub rate_limit_per_source: u32,
    pub rate_limit_window: Duration,
}

impl Default for AggregatorConfig {
    fn default() -> Self {
        Self {
            dedup_window: Duration::from_secs(30),
            scan_dedup_window: Duration::from_secs(3600), // 1 hour for scans
            rate_limit_per_source: 20,
            rate_limit_window: Duration::from_secs(60),
        }
    }
}
```

In `is_duplicate`, select window based on source:

```rust
fn is_duplicate(&mut self, alert: &Alert) -> bool {
    let key = Self::dedup_key(alert);
    let now = Instant::now();
    let window = if alert.source.starts_with("scan:") {
        self.config.scan_dedup_window
    } else {
        self.config.dedup_window
    };

    if let Some(entry) = self.dedup_map.get_mut(&key) {
        if now.duration_since(entry.last_seen) < window {
            entry.suppressed_count += 1;
            entry.last_seen = now;
            return true;
        }
        entry.last_seen = now;
        entry.suppressed_count = 0;
        false
    } else {
        self.dedup_map.insert(key, DeduplicationEntry {
            last_seen: now,
            suppressed_count: 0,
        });
        false
    }
}
```

**Step 6: Run all tests**

```bash
cargo test
```

**Step 7: Commit**

```bash
git add src/aggregator.rs
git commit -m "feat: fuzzy alert deduplication with scan-specific window"
```

---

## Task 3: Network Allowlist (LAN/mDNS/Multicast)

Expand `is_known_good_destination` and make it config-driven with CIDR support.

**Files:**
- Modify: `Cargo.toml` (add `ipnet`)
- Modify: `src/config.rs`
- Modify: `src/network.rs`

**Step 1: Add ipnet dependency**

In `Cargo.toml` under `[dependencies]`:

```toml
ipnet = "2"
```

**Step 2: Add network allowlist config**

In `src/config.rs`, add fields to `NetworkConfig`:

```rust
#[derive(Debug, Deserialize, Serialize, Clone)]
pub struct NetworkConfig {
    pub log_path: String,
    pub log_prefix: String,
    pub enabled: bool,
    #[serde(default = "default_network_source")]
    pub source: String,
    /// CIDR ranges to never alert on (e.g. "192.168.0.0/16", "10.0.0.0/8")
    #[serde(default = "default_allowlisted_cidrs")]
    pub allowlisted_cidrs: Vec<String>,
    /// Ports to never alert on (in addition to 443, 53, 123)
    #[serde(default = "default_allowlisted_ports")]
    pub allowlisted_ports: Vec<u16>,
}

fn default_allowlisted_cidrs() -> Vec<String> {
    vec![
        "192.168.0.0/16".to_string(),
        "10.0.0.0/8".to_string(),
        "172.16.0.0/12".to_string(),
        "169.254.0.0/16".to_string(),
        "127.0.0.0/8".to_string(),
        "224.0.0.0/4".to_string(),  // multicast
    ]
}

fn default_allowlisted_ports() -> Vec<u16> {
    vec![443, 53, 123, 5353]
}
```

**Step 3: Write test for network allowlisting**

Add to `src/network.rs` tests:

```rust
#[test]
fn test_lan_traffic_allowed() {
    assert!(is_known_good_destination_with_config("192.168.1.50", "8080", &default_network_allowlist()));
}

#[test]
fn test_mdns_allowed() {
    assert!(is_known_good_destination_with_config("224.0.0.251", "5353", &default_network_allowlist()));
}

#[test]
fn test_public_ip_not_allowed() {
    assert!(!is_known_good_destination_with_config("8.8.8.8", "8080", &default_network_allowlist()));
}

#[test]
fn test_known_port_allowed() {
    assert!(is_known_good_destination_with_config("8.8.8.8", "443", &default_network_allowlist()));
}
```

**Step 4: Implement config-driven allowlist**

Replace/refactor `is_known_good_destination` in `src/network.rs`:

```rust
use std::net::IpAddr;
use ipnet::IpNet;

pub struct NetworkAllowlist {
    cidrs: Vec<IpNet>,
    ports: Vec<u16>,
}

impl NetworkAllowlist {
    pub fn from_config(cidrs: &[String], ports: &[u16]) -> Self {
        let parsed_cidrs: Vec<IpNet> = cidrs.iter()
            .filter_map(|c| c.parse().ok())
            .collect();
        Self {
            cidrs: parsed_cidrs,
            ports: ports.to_vec(),
        }
    }

    pub fn is_allowed(&self, dst: &str, dpt: &str) -> bool {
        // Check port
        if let Ok(port) = dpt.parse::<u16>() {
            if self.ports.contains(&port) {
                return true;
            }
        }
        // Check CIDR
        if let Ok(ip) = dst.parse::<IpAddr>() {
            for cidr in &self.cidrs {
                if cidr.contains(&ip) {
                    return true;
                }
            }
        }
        false
    }
}
```

Update callers to use the new struct (pass config through from main).

**Step 5: Run tests**

```bash
cargo test
```

**Step 6: Commit**

```bash
git add Cargo.toml src/config.rs src/network.rs
git commit -m "feat: config-driven network allowlist with CIDR support"
```

---

## Task 4: Agent vs Human Attribution via auid

The agent runs as a systemd service â†’ auid=4294967295 (unset). Human SSH sessions have auid matching their login UID. Use this to tag alerts.

**Files:**
- Modify: `src/auditd.rs`
- Modify: `src/alerts.rs`

**Step 1: Write test**

Add to `src/auditd.rs` tests:

```rust
#[test]
fn test_extract_auid_agent() {
    let line = r#"type=SYSCALL msg=audit(1707849600.123:456): arch=c00000b7 syscall=221 success=yes uid=1000 auid=4294967295 exe="/usr/bin/curl""#;
    let event = parse_to_event(line, Some(&["1000".to_string()])).unwrap();
    assert_eq!(event.actor, Actor::Agent);
}

#[test]
fn test_extract_auid_human() {
    let line = r#"type=SYSCALL msg=audit(1707849600.123:456): arch=c00000b7 syscall=221 success=yes uid=1000 auid=1000 exe="/usr/bin/curl""#;
    let event = parse_to_event(line, Some(&["1000".to_string()])).unwrap();
    assert_eq!(event.actor, Actor::Human);
}
```

**Step 2: Run test to verify it fails**

```bash
cargo test test_extract_auid -- --nocapture
```

**Step 3: Add Actor enum and field to ParsedEvent**

In `src/auditd.rs`:

```rust
#[derive(Debug, Clone, PartialEq, Eq)]
pub enum Actor {
    Agent,
    Human,
    Unknown,
}

#[derive(Debug, Clone)]
pub struct ParsedEvent {
    pub syscall_name: String,
    pub command: Option<String>,
    pub args: Vec<String>,
    pub file_path: Option<String>,
    pub success: bool,
    pub raw: String,
    pub actor: Actor,  // NEW
}
```

In `parse_to_event`, for SYSCALL records, extract auid:

```rust
let auid = extract_field(line, "auid").and_then(|s| s.parse::<u32>().ok());
let actor = match auid {
    Some(4294967295) | None => Actor::Agent,  // unset auid = systemd service
    Some(_) => Actor::Human,
};
```

Set `actor: Actor::Unknown` for EXECVE-only records (they inherit from preceding SYSCALL).

**Step 4: Tag alerts with actor**

In `event_to_alert`, prepend actor tag:

```rust
let actor_tag = match event.actor {
    Actor::Agent => "[AGENT] ",
    Actor::Human => "[HUMAN] ",
    Actor::Unknown => "",
};
// Use format!("{}{}", actor_tag, msg) in alert message
```

**Step 5: Run all tests, fix any broken ones**

```bash
cargo test
```

Update existing tests that construct `ParsedEvent` to include the new `actor` field.

**Step 6: Commit**

```bash
git add src/auditd.rs src/alerts.rs
git commit -m "feat: agent vs human attribution via auid tagging"
```

---

## Task 5: Compiler/Linker False Positive Fix

Extract `ppid` and parent exe from SYSCALL records. Suppress SEC_TAMPER when parent is a build tool.

**Files:**
- Modify: `src/auditd.rs`
- Modify: `src/behavior.rs`

**Step 1: Write test**

Add to `src/behavior.rs` tests:

```rust
#[test]
fn test_linker_under_cargo_not_flagged() {
    let event = ParsedEvent {
        syscall_name: "execve".to_string(),
        command: Some("ld-linux-aarch64.so.1 --dynamic-linker /lib/ld-linux-aarch64.so.1".to_string()),
        args: vec!["ld-linux-aarch64.so.1".to_string()],
        file_path: None,
        success: true,
        raw: String::new(),
        actor: Actor::Unknown,
        ppid_exe: Some("/usr/bin/collect2".to_string()),
    };
    assert!(classify_behavior(&event).is_none());
}

#[test]
fn test_linker_standalone_still_flagged() {
    let event = ParsedEvent {
        syscall_name: "execve".to_string(),
        command: Some("ld-linux-aarch64.so.1 /tmp/exploit".to_string()),
        args: vec!["ld-linux-aarch64.so.1".to_string()],
        file_path: None,
        success: true,
        raw: String::new(),
        actor: Actor::Unknown,
        ppid_exe: Some("/usr/bin/bash".to_string()),
    };
    let result = classify_behavior(&event);
    assert!(result.is_some());
}
```

**Step 2: Add ppid_exe to ParsedEvent**

In `src/auditd.rs`, add to `ParsedEvent`:

```rust
pub ppid_exe: Option<String>,  // NEW: parent process exe path
```

For SYSCALL records, extract `ppid=` and read `/proc/<ppid>/exe`:

```rust
let ppid = extract_field(line, "ppid").and_then(|s| s.parse::<u32>().ok());
let ppid_exe = ppid.and_then(|p| {
    std::fs::read_link(format!("/proc/{}/exe", p)).ok()
        .map(|path| path.to_string_lossy().to_string())
});
```

**Step 3: Update behavior.rs to check parent**

Add a constant:

```rust
const BUILD_TOOL_BASES: &[&str] = &[
    "cargo", "rustc", "cc", "cc1", "cc1plus", "gcc", "g++",
    "collect2", "ld", "make", "cmake", "ninja", "as",
];
```

In the dynamic linker detection (around line 410), before returning SEC_TAMPER:

```rust
if binary == "ld-linux-aarch64.so.1" || binary.starts_with("ld-linux") || binary == "ld.so" {
    if let Some(ref ppid_exe) = event.ppid_exe {
        let parent_base = ppid_exe.rsplit('/').next().unwrap_or(ppid_exe);
        if BUILD_TOOL_BASES.iter().any(|t| parent_base.starts_with(t)) {
            return None; // Normal build process
        }
    }
    return Some((BehaviorCategory::SecurityTamper, Severity::Critical));
}
```

Similarly update the PRELOAD_BYPASS_PATTERNS check (~line 391) to also consider parent exe.

**Step 4: Run all tests**

```bash
cargo test
```

Fix any tests that construct ParsedEvent without the new field.

**Step 5: Commit**

```bash
git add src/auditd.rs src/behavior.rs
git commit -m "feat: suppress compiler/linker false positives via parent process check"
```

---

## Task 6: Health Heartbeat

Add a `/api/health` endpoint and a periodic Slack "I'm alive" ping.

**Files:**
- Modify: `src/api.rs`
- Modify: `src/slack.rs`
- Modify: `src/main.rs`
- Modify: `src/config.rs`

**Step 1: Add health config**

In `src/config.rs`, add to `SlackConfig`:

```rust
/// Interval in seconds for periodic health heartbeat to Slack (0 = disabled)
#[serde(default = "default_heartbeat_interval")]
pub heartbeat_interval: u64,
```

```rust
fn default_heartbeat_interval() -> u64 {
    3600 // 1 hour
}
```

**Step 2: Add health endpoint**

In `src/api.rs`, add handler for `GET /api/health`:

```rust
"/api/health" => {
    let store = alert_store.lock().await;
    let alerts = store.last_n(1);
    let last_alert_age = alerts.first()
        .map(|a| (chrono::Local::now() - a.timestamp).num_seconds())
        .unwrap_or(999999);
    
    let uptime = start_time.elapsed().as_secs();
    let healthy = uptime < 120 || last_alert_age < 7200; // startup grace or recent activity
    
    let body = serde_json::json!({
        "healthy": healthy,
        "uptime_seconds": uptime,
        "last_alert_seconds_ago": last_alert_age,
        "version": env!("CARGO_PKG_VERSION"),
    });
    
    let status = if healthy { 200 } else { 503 };
    // Return appropriate response
}
```

Note: You'll need to pass `start_time: Instant` into the API handler. Add it to the API server state.

**Step 3: Add Slack heartbeat**

In `src/slack.rs`:

```rust
pub async fn send_heartbeat(&self, uptime_secs: u64, alert_count: u64) -> Result<()> {
    if !self.enabled { return Ok(()); }
    
    let payload = serde_json::json!({
        "channel": self.channel,
        "username": "ClawTower",
        "icon_emoji": ":shield:",
        "text": format!("ðŸ’š ClawTower heartbeat â€” uptime: {}h {}m, alerts processed: {}",
            uptime_secs / 3600, (uptime_secs % 3600) / 60, alert_count)
    });
    
    self.post_webhook(&payload).await
}
```

**Step 4: Spawn heartbeat task in main.rs**

In `src/main.rs`, after the Slack startup message:

```rust
// Spawn periodic health heartbeat
let heartbeat_interval = config.slack.heartbeat_interval;
if heartbeat_interval > 0 {
    let heartbeat_notifier = SlackNotifier::new(&config.slack);
    let start = std::time::Instant::now();
    tokio::spawn(async move {
        let mut interval = tokio::time::interval(Duration::from_secs(heartbeat_interval));
        interval.tick().await; // skip first immediate tick
        loop {
            interval.tick().await;
            let uptime = start.elapsed().as_secs();
            if let Err(e) = heartbeat_notifier.send_heartbeat(uptime, 0).await {
                eprintln!("Heartbeat send error: {}", e);
            }
        }
    });
}
```

**Step 5: Run tests and verify compilation**

```bash
cargo test
cargo build
```

**Step 6: Commit**

```bash
git add src/api.rs src/slack.rs src/main.rs src/config.rs
git commit -m "feat: health endpoint and periodic Slack heartbeat"
```

---

## Task 7: Ed25519 Update Signature Verification

Add cryptographic signing to the release pipeline and verification to the update path.

**Files:**
- Modify: `Cargo.toml` (add `ed25519-dalek`)
- Modify: `src/update.rs`
- Create: `scripts/sign-release.sh`
- Modify: `.github/workflows/release.yml`

**Step 1: Add ed25519-dalek dependency**

```toml
ed25519-dalek = { version = "2", features = ["std"] }
```

**Step 2: Generate signing keypair**

Create `scripts/sign-release.sh`:

```bash
#!/usr/bin/env bash
# Sign a release binary with Ed25519
# Usage: ./sign-release.sh <binary> <private-key-file>
set -euo pipefail

BINARY="$1"
PRIVKEY="$2"

# Generate signature using openssl
openssl pkeyutl -sign -inkey "$PRIVKEY" -rawinput -in <(sha256sum "$BINARY" | cut -d' ' -f1 | xxd -r -p) -out "${BINARY}.sig"

echo "Signed: ${BINARY}.sig"
```

Note: For production, we'll use ed25519-dalek in a small Rust signing tool. For now, embed the public key and verify in the update path.

**Step 3: Create signing keygen tool**

Create `scripts/generate-release-key.sh`:

```bash
#!/usr/bin/env bash
# Generate Ed25519 keypair for release signing
# Private key: release-key.pem (keep in CI secrets, NEVER commit)
# Public key: release-key.pub (embed in binary)
set -euo pipefail

openssl genpkey -algorithm ed25519 -out release-key.pem
openssl pkey -in release-key.pem -pubout -outform DER | tail -c 32 > src/release-key.pub

echo "Private key: release-key.pem (add to CI secrets as RELEASE_SIGNING_KEY)"
echo "Public key:  src/release-key.pub (committed, embedded in binary)"
```

**Step 4: Write verification code**

In `src/update.rs`, add:

```rust
use ed25519_dalek::{Verifier, VerifyingKey, Signature};

/// Embedded Ed25519 public key for release verification
const RELEASE_PUBLIC_KEY: &[u8; 32] = include_bytes!("release-key.pub");

fn verify_release_signature(binary_data: &[u8], sig_bytes: &[u8]) -> Result<()> {
    if sig_bytes.len() != 64 {
        bail!("Invalid signature length: {} (expected 64)", sig_bytes.len());
    }
    
    let pubkey = VerifyingKey::from_bytes(RELEASE_PUBLIC_KEY)
        .context("Invalid embedded public key")?;
    
    // Sign over SHA256 of binary (not raw binary â€” too large)
    let mut hasher = Sha256::new();
    hasher.update(binary_data);
    let digest = hasher.finalize();
    
    let sig = Signature::from_bytes(sig_bytes.try_into()
        .context("Signature wrong length")?);
    
    pubkey.verify(&digest, &sig)
        .context("âŒ SIGNATURE VERIFICATION FAILED â€” binary may be tampered")?;
    
    eprintln!("âœ… Ed25519 signature verified");
    Ok(())
}
```

**Step 5: Integrate into download flow**

In `fetch_release`, also look for `.sig` asset. In the download flow after SHA256 check:

```rust
// Download and verify Ed25519 signature
if let Some(sig_url) = sig_url {
    let sig_data = client.get(&sig_url).send()?.error_for_status()?.bytes()?.to_vec();
    verify_release_signature(&binary_data, &sig_data)?;
} else {
    bail!("âŒ Release has no .sig file â€” refusing to install unsigned binary");
}
```

**Step 6: Update CI release workflow**

In `.github/workflows/release.yml`, add signing step after build:

```yaml
- name: Sign release binaries
  env:
    RELEASE_SIGNING_KEY: ${{ secrets.RELEASE_SIGNING_KEY }}
  run: |
    echo "$RELEASE_SIGNING_KEY" | base64 -d > /tmp/release-key.pem
    for binary in target/*/release/clawtower; do
      # Create signature
      sha256sum "$binary" | cut -d' ' -f1 | xxd -r -p > /tmp/digest
      openssl pkeyutl -sign -inkey /tmp/release-key.pem -rawinput -in /tmp/digest -out "${binary}.sig"
    done
    rm -f /tmp/release-key.pem /tmp/digest
```

Add `.sig` files to the release upload step.

**Step 7: Generate initial keypair (DO NOT COMMIT private key)**

```bash
cd /path/to/ClawTower
./scripts/generate-release-key.sh
# Add release-key.pem contents to GitHub repo secret: RELEASE_SIGNING_KEY
# Commit src/release-key.pub
```

Note: Until the keypair is generated, use a placeholder 32-byte file for `src/release-key.pub` so compilation works:

```bash
dd if=/dev/urandom bs=32 count=1 > src/release-key.pub 2>/dev/null
```

**Step 8: Run tests**

```bash
cargo test
cargo build
```

**Step 9: Commit**

```bash
git add Cargo.toml src/update.rs src/release-key.pub scripts/sign-release.sh scripts/generate-release-key.sh .github/workflows/release.yml
git commit -m "feat: Ed25519 signature verification for updates"
```

---

## Task 8: Alert Persistence (JSONL)

Write all aggregated alerts to a JSONL file for queryable history that survives restarts.

**Files:**
- Modify: `src/aggregator.rs`
- Modify: `src/api.rs`

**Step 1: Write test**

```rust
#[test]
fn test_alert_serializes_to_json() {
    let alert = Alert::new(Severity::Warning, "test", "hello world");
    let json = serde_json::to_string(&alert).unwrap();
    assert!(json.contains("hello world"));
    assert!(json.contains("test"));
}
```

**Step 2: Add JSONL writer in aggregator**

In `run_aggregator`, after the audit chain append:

```rust
// Append to persistent JSONL log
let alerts_log_path = if unsafe { libc::getuid() } == 0 {
    "/var/log/clawtower/alerts.jsonl".to_string()
} else {
    format!("/tmp/clawtower-{}/alerts.jsonl", unsafe { libc::getuid() })
};

// Inside the loop, after audit chain append:
if let Ok(mut file) = std::fs::OpenOptions::new()
    .create(true).append(true)
    .open(&alerts_log_path)
{
    if let Ok(json) = serde_json::to_string(&alert) {
        let _ = writeln!(file, "{}", json);
    }
}
```

**Step 3: Add log rotation**

In the periodic cleanup section (every 100 alerts), check file size:

```rust
if cleanup_counter >= 100 {
    aggregator.cleanup();
    // Rotate log if > 10MB
    if let Ok(meta) = std::fs::metadata(&alerts_log_path) {
        if meta.len() > 10_000_000 {
            let rotated = format!("{}.1", alerts_log_path);
            let _ = std::fs::rename(&alerts_log_path, &rotated);
        }
    }
    cleanup_counter = 0;
}
```

**Step 4: Add history API endpoint**

In `src/api.rs`, add `GET /api/alerts/history?since=<epoch>&severity=<level>&limit=<n>`:

Read from JSONL file, filter, return JSON array. Keep implementation simple â€” read last N lines, parse, filter.

**Step 5: Run tests**

```bash
cargo test
```

**Step 6: Commit**

```bash
git add src/aggregator.rs src/api.rs
git commit -m "feat: persistent alert history in JSONL with rotation"
```

---

## Task 9: SSH Login Monitoring

Real-time SSH login alerts via journald.

**Files:**
- Modify: `src/journald.rs`
- Modify: `src/config.rs`
- Modify: `src/main.rs`

**Step 1: Add SSH config toggle**

In `src/config.rs`, add to a new section or under `general`:

```rust
#[derive(Debug, Deserialize, Serialize, Clone, Default)]
pub struct SshConfig {
    #[serde(default = "default_true")]
    pub enabled: bool,
}

fn default_true() -> bool { true }
```

Add `ssh: SshConfig` to `Config` struct with `#[serde(default)]`.

**Step 2: Add SSH monitor function**

In `src/journald.rs`:

```rust
pub async fn tail_journald_ssh(tx: mpsc::Sender<Alert>) -> Result<()> {
    use tokio::io::{AsyncBufReadExt, BufReader};
    use tokio::process::Command;

    let mut child = Command::new("journalctl")
        .args(["-u", "ssh", "-u", "sshd", "-f", "-o", "cat", "--since", "now"])
        .stdout(std::process::Stdio::piped())
        .stderr(std::process::Stdio::null())
        .spawn()
        .context("Failed to spawn journalctl for SSH monitoring")?;

    let stdout = child.stdout.take().context("No stdout")?;
    let mut reader = BufReader::new(stdout).lines();

    while let Some(line) = reader.next_line().await? {
        let (severity, msg) = if line.contains("Accepted") {
            (Severity::Info, format!("SSH login: {}", line))
        } else if line.contains("Failed password") || line.contains("Failed publickey") {
            (Severity::Warning, format!("SSH failed login: {}", line))
        } else if line.contains("Invalid user") {
            (Severity::Warning, format!("SSH invalid user: {}", line))
        } else {
            continue;
        };

        let _ = tx.send(Alert::new(severity, "ssh", &msg)).await;
    }

    Ok(())
}
```

**Step 3: Spawn in main.rs**

In `src/main.rs`, alongside other monitor spawns:

```rust
if config.ssh.enabled {
    let tx = raw_tx.clone();
    tokio::spawn(async move {
        if let Err(e) = journald::tail_journald_ssh(tx).await {
            eprintln!("SSH monitor error: {}", e);
        }
    });
}
```

**Step 4: Run tests**

```bash
cargo test
cargo build
```

**Step 5: Commit**

```bash
git add src/journald.rs src/config.rs src/main.rs
git commit -m "feat: real-time SSH login monitoring via journald"
```

---

## Task 10: Scan Timeouts

Prevent scan functions from hanging on slow storage.

**Files:**
- Modify: `src/scanner.rs`

**Step 1: Add timeout wrapper**

Replace `run_cmd` and `run_cmd_with_sudo` with timeout versions:

```rust
fn run_cmd_timeout(cmd: &str, args: &[&str], timeout_secs: u64) -> Result<String, String> {
    let mut child = std::process::Command::new(cmd)
        .args(args)
        .stdout(std::process::Stdio::piped())
        .stderr(std::process::Stdio::null())
        .spawn()
        .map_err(|e| format!("Failed to spawn {}: {}", cmd, e))?;

    let start = std::time::Instant::now();
    loop {
        match child.try_wait() {
            Ok(Some(_status)) => {
                let output = child.wait_with_output()
                    .map_err(|e| format!("Failed to get output: {}", e))?;
                return Ok(String::from_utf8_lossy(&output.stdout).to_string());
            }
            Ok(None) => {
                if start.elapsed().as_secs() > timeout_secs {
                    let _ = child.kill();
                    return Err(format!("{} timed out after {}s", cmd, timeout_secs));
                }
                std::thread::sleep(std::time::Duration::from_millis(100));
            }
            Err(e) => return Err(format!("Error waiting for {}: {}", cmd, e)),
        }
    }
}
```

**Step 2: Update callers**

Replace `run_cmd("find", ...)` calls with `run_cmd_timeout("find", ..., 30)`. Use 30s default for most scans, 60s for deep scans like `dpkg --verify`.

**Step 3: Run tests**

```bash
cargo test
cargo build
```

**Step 4: Commit**

```bash
git add src/scanner.rs
git commit -m "feat: scan command timeouts to prevent hangs"
```

---

## Task 11: `clawtower config` CLI

Add `clawtower config get` and `clawtower config set` subcommands.

**Files:**
- Modify: `src/main.rs`
- Modify: `src/admin.rs`

**Step 1: Add config subcommand to main.rs**

In the CLI match block:

```rust
"config" => {
    match args.get(2).map(|s| s.as_str()) {
        Some("get") => {
            let config = Config::load(&config_path)?;
            if let Some(field) = args.get(3) {
                // Print specific field (dotted path)
                println!("{}", get_config_field(&config, field)?);
            } else {
                // Print whole config as TOML
                println!("{}", toml::to_string_pretty(&config)?);
            }
        }
        Some("set") => {
            let field = args.get(3).context("Usage: clawtower config set <field> <value>")?;
            let value = args.get(4).context("Usage: clawtower config set <field> <value>")?;
            
            // Require admin key
            let key = get_admin_key(&args[2..])?;
            if !verify_admin_key(&key)? {
                bail!("Invalid admin key");
            }
            
            // chattr -i, load, modify, save, chattr +i
            let _ = std::process::Command::new("chattr")
                .args(["-i", &config_path.to_string_lossy()]).status();
            let mut config = Config::load(&config_path)?;
            set_config_field(&mut config, field, value)?;
            config.save(&config_path)?;
            let _ = std::process::Command::new("chattr")
                .args(["+i", &config_path.to_string_lossy()]).status();
            
            println!("âœ… Set {} = {}", field, value);
            println!("Restart clawtower for changes to take effect.");
        }
        _ => {
            eprintln!("Usage: clawtower config [get|set] [field] [value]");
        }
    }
    return Ok(());
}
```

**Step 2: Implement field accessors**

Add helper functions for dotted-path config access:

```rust
fn get_config_field(config: &Config, field: &str) -> Result<String> {
    // Serialize to Value, navigate dotted path
    let value = toml::Value::try_from(config)?;
    let parts: Vec<&str> = field.split('.').collect();
    let mut current = &value;
    for part in &parts {
        current = current.get(part)
            .with_context(|| format!("Unknown config field: {}", field))?;
    }
    Ok(current.to_string())
}

fn set_config_field(config: &mut Config, field: &str, value: &str) -> Result<()> {
    // Serialize to Value, navigate, set, deserialize back
    let mut val = toml::Value::try_from(&*config)?;
    let parts: Vec<&str> = field.split('.').collect();
    let mut current = &mut val;
    for (i, part) in parts.iter().enumerate() {
        if i == parts.len() - 1 {
            // Set the value â€” try to preserve type
            if let Some(table) = current.as_table_mut() {
                let new_val = if value == "true" || value == "false" {
                    toml::Value::Boolean(value.parse().unwrap())
                } else if let Ok(n) = value.parse::<i64>() {
                    toml::Value::Integer(n)
                } else {
                    toml::Value::String(value.to_string())
                };
                table.insert(part.to_string(), new_val);
            }
        } else {
            current = current.get_mut(part)
                .with_context(|| format!("Unknown config section: {}", part))?;
        }
    }
    *config = val.try_into().context("Failed to apply config change")?;
    Ok(())
}
```

**Step 3: Run tests**

```bash
cargo test
cargo build
```

**Step 4: Commit**

```bash
git add src/main.rs
git commit -m "feat: clawtower config get/set CLI commands"
```

---

## Task 12: Config-Driven Allowlist

Add a general `[allowlist]` section for suppressing known-good patterns.

**Files:**
- Modify: `src/config.rs`
- Modify: `src/aggregator.rs`

**Step 1: Add allowlist config**

In `src/config.rs`:

```rust
#[derive(Debug, Deserialize, Serialize, Clone, Default)]
pub struct AllowlistConfig {
    /// Regex patterns on alert messages to suppress
    #[serde(default)]
    pub alert_patterns: Vec<String>,
    /// Process name patterns to never alert on
    #[serde(default)]
    pub processes: Vec<String>,
}
```

Add to `Config`:

```rust
#[serde(default)]
pub allowlist: AllowlistConfig,
```

**Step 2: Apply in aggregator**

Pass allowlist config to `Aggregator`. In `process()`, before dedup check:

```rust
// Check allowlist patterns
for pattern in &self.allowlist_patterns {
    if pattern.is_match(&alert.message) {
        return None; // Suppressed by allowlist
    }
}
```

Compile regex patterns once in `Aggregator::new`:

```rust
pub struct Aggregator {
    config: AggregatorConfig,
    dedup_map: HashMap<String, DeduplicationEntry>,
    rate_limits: HashMap<String, RateLimitEntry>,
    allowlist_patterns: Vec<regex::Regex>,  // NEW
}
```

**Step 3: Write test**

```rust
#[test]
fn test_allowlist_suppresses_matching_alert() {
    let mut agg = Aggregator::new_with_allowlist(
        AggregatorConfig::default(),
        vec![regex::Regex::new(r"\[BEHAVIOR:RECON\].*uname").unwrap()],
    );
    let a = make_alert("behavior", "[BEHAVIOR:RECON] exec: uname -a", Severity::Info);
    assert!(agg.process(a).is_none());
}
```

**Step 4: Run tests**

```bash
cargo test
```

**Step 5: Commit**

```bash
git add src/config.rs src/aggregator.rs
git commit -m "feat: config-driven alert allowlist patterns"
```

---

## Task 13: Documentation

**Files:**
- Create: `docs/CONFIGURATION.md`
- Create: `docs/TROUBLESHOOTING.md`
- Create: `CHANGELOG.md`
- Modify: `README.md`

**Step 1: Write CONFIGURATION.md**

Document every config section and field with defaults and examples. Use the `Config` struct in `src/config.rs` as the source of truth.

**Step 2: Write TROUBLESHOOTING.md**

Cover:
- Too many alerts â†’ configure allowlist, check dedup settings
- Scan timeouts â†’ increase timeout or disable slow scans
- Slack webhook not working â†’ test with `clawtower test-webhook`
- High CPU usage â†’ reduce scan frequency
- False positives from cargo build â†’ explained and fixed in v0.3.1

**Step 3: Write CHANGELOG.md**

```markdown
# Changelog

## [0.2.0] - 2026-02-XX

### Added
- Fuzzy alert deduplication (normalizes numbers/PIDs in messages)
- Scan-specific dedup window (1 hour default for periodic scans)
- Config-driven network allowlist with CIDR support
- Agent vs human attribution via auid tagging ([AGENT]/[HUMAN] prefixes)
- Compiler/linker false positive suppression via parent process detection
- Health endpoint (`GET /api/health`) and periodic Slack heartbeat
- Ed25519 signature verification for self-updates
- Persistent alert history in JSONL with log rotation
- Real-time SSH login monitoring via journald
- Scan command timeouts (prevents hangs on slow storage)
- `clawtower config get/set` CLI commands
- Config-driven alert allowlist patterns
- Configuration reference docs
- Troubleshooting guide

### Fixed
- Compiler/linker invocations (ld, collect2, cc) no longer trigger SEC_TAMPER alerts during normal builds
- mDNS, LAN, and Docker traffic no longer generates network warnings
- Scan results with varying counts no longer bypass dedup

### Security
- Self-update now requires Ed25519 signature verification (embedded public key)
- Unsigned or tampered releases are rejected
```

**Step 4: Update README.md**

Add links to new docs. Update feature list.

**Step 5: Commit**

```bash
git add docs/CONFIGURATION.md docs/TROUBLESHOOTING.md CHANGELOG.md README.md
git commit -m "docs: add configuration reference, troubleshooting, and changelog for v0.3.1"
```

---

## Task 14: Final Verification

**Step 1: Run full test suite**

```bash
cargo test
```

Expected: All tests pass.

**Step 2: Build release**

```bash
cargo build --release
```

Expected: Clean compile, no warnings.

**Step 3: Verify binary runs**

```bash
./target/release/clawtower --help
./target/release/clawtower config get
```

**Step 4: Tag release**

```bash
git tag -a v0.3.1 -m "v0.3.1: noise reduction, attribution, signing, monitoring"
git push origin main --tags
```

This triggers CI to build and publish the release.
